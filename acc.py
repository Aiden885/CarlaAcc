import carla
import math
import numpy as np
import cv2
import csv
import time
import lane_detection
import kalman_filter
import radar_cluster
import pygame
import threading
from collections import deque
from acc_planning_control import ACCPlanningControl
from sinusoidal_speed_controller import SinusoidalSpeedController
# from carla_3d_trajectory_visualizer import CarlaTrajectoryVisualizer
# from realtime_trajectory_manager import BSplineTrajectoryManager, RealTimeTrajectoryBuffer


class acc:
    def __init__(self):
        self.tracker = kalman_filter.RadarTracker()
        self.lane_detector = lane_detection.LaneDetector()
        self.radar_point_cluster = radar_cluster.RadarClusterNode()
        self.max_follow_distance = 50
        self.radar_detections = []
        self.latest_camera_image = None
        self.radar_2_world = []
        self.world_2_camera = []
        self.cluster = []
        self.track_id = []
        self.image_width = 1280
        self.image_height = 720
        self.target_vehicle = None
        self.start_time = None
        self.csv_file = None
        self.csv_writer = None
        self.target_speed_controller = None

        # === æ–°å¢ï¼šè½¨è¿¹ç®¡ç†ç³»ç»Ÿ ===
        # # 1. åˆ›å»ºè½¨è¿¹ç¼“å†²åŒº
        # self.trajectory_buffer = RealTimeTrajectoryBuffer(
        #     max_length=50.0,  # æœ€å¤§è½¨è¿¹é•¿åº¦50ç±³
        #     spatial_resolution=0.3  # ç©ºé—´åˆ†è¾¨ç‡0.3ç±³/ç‚¹
        # )
        #
        # # 2. åˆ›å»ºè½¨è¿¹ç®¡ç†å™¨
        # self.trajectory_manager = BSplineTrajectoryManager(
        #     trajectory_buffer=self.trajectory_buffer,
        #     min_points_for_fit=5,  # æœ€å°‘5ä¸ªç‚¹æ‰è¿›è¡Œæ‹Ÿåˆ
        #     fit_interval=3  # æ¯3å¸§æ›´æ–°ä¸€æ¬¡æ‹Ÿåˆ
        # )
        #
        # # 3. æ€§èƒ½ç›‘æ§
        # self.frame_times = deque(maxlen=100)
        # self.last_frame_time = None
        #
        # # 4. è½¨è¿¹çŠ¶æ€ç›‘æ§
        # self.trajectory_stats = {
        #     'total_updates': 0,
        #     'successful_fits': 0,
        #     'last_waypoint_count': 0
        # }

        # === æ–°å¢ï¼š3Dè½¨è¿¹å¯è§†åŒ–å™¨ ===
        self.trajectory_visualizer = None  # å°†åœ¨init_carlaååˆå§‹åŒ–

        # å¯è§†åŒ–é…ç½®
        self.visualization_config = {
            'enable_3d_trajectory': True,
            'enable_curvature_visualization': True,
            'enable_tangent_visualization': True,
            'enable_speed_visualization': False,
            'enable_lookahead_visualization': True,
            'update_frequency': 1,  # æ¯å¸§æ›´æ–°
            'frame_counter': 0
        }

        self.init_carla()
        self.init_csv()


    def init_carla(self):
        # åˆå§‹åŒ– Carla å®¢æˆ·ç«¯
        self.client = carla.Client('localhost', 2000)
        self.client.set_timeout(30.0)
        try:
            self.world = self.client.get_world()
            self.world = self.client.load_world('Town05', carla.MapLayer.Buildings | carla.MapLayer.ParkedVehicles)
        except RuntimeError as e:
            raise RuntimeError(f"Failed to load map Town05: {e}")

        # è·å–è“å›¾åº“å’Œåœ°å›¾
        self.blueprint_library = self.world.get_blueprint_library()
        map = self.world.get_map()


        # è·å–è½¦è¾†è“å›¾
        vehicle_bp = self.blueprint_library.filter('vehicle.tesla.model3')[0]
        ego_vehicle_bp = self.blueprint_library.filter('vehicle.audi.etron')[0]

        # å®šä¹‰å›ºå®šç”Ÿæˆç‚¹ï¼ˆä¸Šå¡ Town05ï¼‰
        # fixed_point = carla.Location(x=0.663731, y=-203.651886, z=0.5)
        # å®šä¹‰å›ºå®šç”Ÿæˆç‚¹ï¼ˆä¸Šå¡ Town05ï¼‰
        # fixed_point = carla.Location(x=0.663731, y=-203.651886, z=0.5)
        #fixed_point = carla.Location(x=-120.663731, y=-203.651886, z=0.5) #curve
        #fixed_point = carla.Location(x=-244.663731, y=-70.651886, z=0.5) #straight
        #fixed_point = carla.Location(x=-114.663731, y=205.651886, z=0) #downhill
        fixed_point = carla.Location(x=-2.7663731, y=205.651886, z=0.5)  # crossroad
        # æ‰¾åˆ°æœ€è¿‘çš„ waypoint
        waypoint = map.get_waypoint(fixed_point, project_to_road=True, lane_type=carla.LaneType.Driving)
        if waypoint is None:
            raise RuntimeError("Failed to find a valid waypoint near the specified location")

        # è®¾ç½®å‰è½¦ç”Ÿæˆç‚¹ï¼ˆåŸºäº waypointï¼‰
        spawn_point = waypoint.transform
        spawn_point.location.z += 0.5  # ç•¥å¾®æŠ¬é«˜ä»¥é¿å…åœ°é¢ç¢°æ’

        # ç”Ÿæˆç›®æ ‡è½¦è¾†
        vehicles = []
        target_vehicle = self.world.try_spawn_actor(vehicle_bp, spawn_point)
        if target_vehicle is None:
            raise RuntimeError("Failed to spawn target vehicle at waypoint location")
        vehicles.append(target_vehicle)
        self.target_vehicle = target_vehicle
        self.target_vehicle.set_autopilot(True)

        # åˆå§‹åŒ–æ­£å¼¦é€Ÿåº¦æ§åˆ¶å™¨
        self.target_speed_controller = SinusoidalSpeedController(
            vehicle=target_vehicle,
            base_speed=20,  # åŸºç¡€é€Ÿåº¦ 20km/h
            amplitude=5.0,  # æŒ¯å¹… 10km/h (é€Ÿåº¦åœ¨ 10-30km/h ä¹‹é—´å˜åŒ–)
            period=10.0  # 10ç§’ä¸€ä¸ªå‘¨æœŸ
        )

        # ç”Ÿæˆè‡ªè½¦ï¼ˆåæ–¹ 15 ç±³ï¼‰
        ego_spawn_point = carla.Transform()
        ego_spawn_point.location = spawn_point.location
        #ego_spawn_point.location.y += 5
        ego_spawn_point.location.x -= 15
        ego_spawn_point.rotation = spawn_point.rotation
        self.ego_vehicle = self.world.try_spawn_actor(ego_vehicle_bp, ego_spawn_point)
        # self.ego_vehicle.set_autopilot(True)



        if self.ego_vehicle is None:
            raise RuntimeError("Failed to spawn ego vehicle")
        self.vehicles = vehicles
        self.ego_vehicle.set_autopilot(False)
        #vehicles.append(self.ego_vehicle)


        # è®¾ç½®äº¤é€šç®¡ç†å™¨
        tm = self.client.get_trafficmanager(8000)
        tm.set_global_distance_to_leading_vehicle(2.0)
        tm.set_synchronous_mode(False)
        self.tm_port = tm.get_port()
        #è‡ªè½¦ä¸å˜é“
        tm.auto_lane_change(self.ego_vehicle,False)

        # è®¾ç½®è½¦è¾†å®Œå…¨å¿½ç•¥äº¤é€šä¿¡å·ç¯
        tm.ignore_lights_percentage(self.ego_vehicle, 100)
        # ç›®æ ‡è½¦è¾†è‡ªåŠ¨é©¾é©¶è®¾ç½®
        for vehicle in vehicles:
            vehicle.set_autopilot(True, self.tm_port)
            tm.auto_lane_change(vehicle, False)
            tm.vehicle_percentage_speed_difference(vehicle, 30.0)

        self.ego_vehicle.set_autopilot(False)

        # è®¾ç½®é€Ÿåº¦æ§åˆ¶å™¨çš„äº¤é€šç®¡ç†å™¨
        if self.target_speed_controller:
            self.target_speed_controller.set_traffic_manager(tm)

        # è®¾ç½®æ‰€æœ‰äº¤é€šä¿¡å·ç¯ä¸ºç»¿è‰²
        traffic_lights = self.world.get_actors().filter('traffic.traffic_light')
        for tl in traffic_lights:
            tl.set_state(carla.TrafficLightState.Green)
            tl.freeze(True)  # é”å®šä¸ºç»¿è‰²ï¼Œé˜²æ­¢è‡ªåŠ¨åˆ‡æ¢
        print(f"Set {len(traffic_lights)} traffic lights to green")

        # é…ç½®ä¼ æ„Ÿå™¨
        radar_bp = self.blueprint_library.find('sensor.other.radar')
        RADAR_CONFIG = {
            'range': '100.0',
            'horizontal_fov': '120.0',
            'vertical_fov': '30.0',
            'points_per_second': '20000'
        }
        for attr, value in RADAR_CONFIG.items():
            radar_bp.set_attribute(attr, value)
        radar_transform = carla.Transform(carla.Location(x=2.0, z=1.0))
        self.radar = self.world.spawn_actor(radar_bp, radar_transform, attach_to=self.ego_vehicle)

        camera_bp = self.blueprint_library.find('sensor.camera.rgb')
        camera_bp.set_attribute('image_size_x', '1280')
        camera_bp.set_attribute('image_size_y', '720')
        camera_bp.set_attribute('fov', '90')
        camera_transform = carla.Transform(carla.Location(x=1.5, z=1.5))
        self.camera = self.world.spawn_actor(camera_bp, camera_transform, attach_to=self.ego_vehicle)

        lidar_bp = self.blueprint_library.find('sensor.lidar.ray_cast')
        lidar_bp.set_attribute('range', '100.0')
        lidar_bp.set_attribute('points_per_second', '1000')
        lidar_bp.set_attribute('rotation_frequency', '10')
        lidar_bp.set_attribute('upper_fov', '10')
        lidar_bp.set_attribute('lower_fov', '-10')
        lidar_transform = carla.Transform(carla.Location(x=0.0, z=2.0))
        self.lidar = self.world.spawn_actor(lidar_bp, lidar_transform, attach_to=self.ego_vehicle)

    def init_csv(self):
        self.csv_file = open('speed_data.csv', 'w', newline='')
        self.csv_writer = csv.writer(self.csv_file)
        # æ·»åŠ æœŸæœ›è·Ÿè½¦è·ç¦»åˆ—
        self.csv_writer.writerow(['Time(s)', 'Ego_Speed(km/h)', 'Target_Speed(km/h)',
                                  'Actual_Distance(m)', 'Desired_Distance(m)', 'Lane_Offset'])
        print("CSV file 'speed_data.csv' created and header written.")

    def get_vehicle_speed(self, vehicle):
        velocity = vehicle.get_velocity()
        speed_m_s = math.sqrt(velocity.x ** 2 + velocity.y ** 2 + velocity.z ** 2)
        speed_kmh = speed_m_s * 3.6
        return speed_kmh

    # æ·»åŠ è®¡ç®—æœŸæœ›è·Ÿè½¦è·ç¦»çš„æ–¹æ³•
    def calculate_desired_following_distance(self, ego_speed_kmh, time_gap=2.0, min_distance=5.0):
        """
        è®¡ç®—æœŸæœ›çš„è·Ÿè½¦è·ç¦»
        :param ego_speed_kmh: è‡ªè½¦é€Ÿåº¦ (km/h)
        :param time_gap: æœŸæœ›æ—¶é—´é—´éš” (ç§’)
        :param min_distance: æœ€å°å®‰å…¨è·ç¦» (ç±³)
        :return: æœŸæœ›è·Ÿè½¦è·ç¦» (ç±³)
        """
        ego_speed_ms = ego_speed_kmh / 3.6  # è½¬æ¢ä¸º m/s
        desired_distance = max(min_distance + ego_speed_ms * time_gap, 15 )
        return desired_distance

    def radar_callback(self, radar_data):
        self.radar_points = []
        self.filted_points = []
        ego_velocity = self.get_vehicle_speed(self.ego_vehicle) / 3.6
        velocity_tolerance = 1.0
        for detection in radar_data:
            try:
                distance = detection.depth
                azimuth = math.degrees(detection.azimuth)
                altitude = math.degrees(detection.altitude)
                velocity = detection.velocity
                x = distance * math.cos(math.radians(altitude)) * math.cos(math.radians(azimuth))
                y = -distance * math.cos(math.radians(altitude)) * math.sin(math.radians(azimuth))
                z = distance * math.sin(math.radians(altitude))
                vx = velocity * math.cos(math.radians(altitude)) * math.cos(math.radians(azimuth))
                vy = velocity * math.cos(math.radians(altitude)) * math.sin(math.radians(azimuth))
                vz = velocity * math.sin(math.radians(altitude))
                expected_static_velocity = -ego_velocity * math.cos(math.radians(azimuth)) * math.cos(
                    math.radians(altitude))
                if z > -0.5:
                    self.radar_points.append([x, y, z, vx, vy, vz, velocity])
                    if abs(velocity - expected_static_velocity) > velocity_tolerance:
                        self.filted_points.append([x, y, z, vx, vy, vz, velocity])
            except AttributeError as e:
                print(f"AttributeError: {e}. Raw detection: {detection}")
        if self.filted_points:
            self.cluster = self.radar_point_cluster.radar_cluster(self.filted_points)
            if self.cluster:
                self.track_id = self.tracker.update(self.cluster)
                for track in self.track_id:
                    if not all(np.isfinite(track)):
                        print(f"Invalid track data: {track}")
                        self.track_id = []
                        break
            else:
                self.track_id = []
                print("No clusters found")
        else:
            self.track_id = []
            print("No filtered points")


    def camera_callback(self, image):
        array = np.frombuffer(image.raw_data, dtype=np.uint8)
        array = array.reshape((image.height, image.width, 4))
        array = array[:, :, :3]
        self.latest_camera_image = array

    def lidar_callback(self, lidar_data):
        points = []
        for point in lidar_data:
            x = point.point.x
            y = point.point.y
            z = point.point.z
            intensity = point.intensity
            points.append([x, y, z, intensity])
        self.latest_lidar_points = points

    def get_extrinsic_params(self, radar_sensor, camera_sensor):
        self.radar_2_world = radar_sensor.get_transform().get_matrix()
        self.world_2_camera = np.array(camera_sensor.get_transform().get_inverse_matrix())

    def project_radar_to_camera(self, radar_points, image_width=1280, image_height=720, fov=90):
        fx = image_width / (2.0 * np.tan(fov * np.pi / 360.0))
        fy = image_height / (2.0 * np.tan(fov * np.pi / 360.0))
        cx = image_width / 2
        cy = image_height / 2
        projected_points = []
        for x, y, z, w, l, h, vx, vy, vz, id in radar_points:
            radar_point = np.array([x, y, z, 1])
            world_point = np.dot(self.radar_2_world, radar_point)
            camera_point = np.dot(self.world_2_camera, world_point)
            point_in_camera_coords = np.array([
                camera_point[1],
                camera_point[2] * -1,
                camera_point[0]])
            u = cx + (fx * point_in_camera_coords[0] / point_in_camera_coords[2])
            v = cy + (fy * point_in_camera_coords[1] / point_in_camera_coords[2])
            ipm_point = np.dot(self.lane_detector.M, np.array([u, v - 300, 1]))
            ipm_point[0] = ipm_point[0] / ipm_point[2]
            ipm_point[1] = ipm_point[1] / ipm_point[2]
            projected_points.append([int(u), int(v), int(ipm_point[0]), int(ipm_point[1])])
        return projected_points

    def get_ipm_transform_matrix(self, camera_sensor, K, image_width=1280, image_height=720):
        camera_height = camera_sensor.get_transform().location.z
        fx, fy = K[0, 0], K[1, 1]
        cx, cy = K[0, 2], K[1, 2]
        src_points = np.float32([
            [image_width * 0.2, image_height],
            [image_width * 0.8, image_height],
            [image_width * 0.6, image_height * 0.4],
            [image_width * 0.4, image_height * 0.4]
        ])
        ground_width = 10.0
        ground_length = 20.0
        dst_points = np.float32([
            [-ground_width / 2, 0],
            [ground_width / 2, 0],
            [ground_width / 2, ground_length],
            [-ground_width / 2, ground_length]
        ])
        H, _ = cv2.findHomography(src_points, dst_points)
        print("Camera IPM Transformation Matrix (Homography H):")
        print(H)
        return H

        # ä¿®å¤ç‰ˆçš„æ‰‹åŠ¨æ§åˆ¶å¤„ç†

    def get_vehicle_distance(self, vehicle1, vehicle2):
        """è®¡ç®—ä¸¤ä¸ªè½¦è¾†ä¹‹é—´çš„è·ç¦»ï¼ˆç±³ï¼‰"""
        if vehicle1 is None or vehicle2 is None:
            return float('inf')

        loc1 = vehicle1.get_location()
        loc2 = vehicle2.get_location()

        # è®¡ç®—2ç»´æ¬§æ°è·ç¦»
        distance = math.sqrt((loc1.x - loc2.x) ** 2 + (loc1.y - loc2.y) ** 2)
        return distance

    def find_best_target(self, track_id, projected_points):
        """ä¼˜åŒ–çš„ç›®æ ‡é€‰æ‹©ç®—æ³•"""
        current_target_idx = -1
        min_distance = float('inf')

        for idx in range(len(track_id)):
            # ç®€åŒ–çš„è½¦é“åˆ¤æ–­
            if -3 < track_id[idx][1] < 3:  # Yåæ ‡åœ¨è½¦é“å†…
                if track_id[idx][0] < min_distance:  # é€‰æ‹©æœ€è¿‘çš„
                    min_distance = track_id[idx][0]
                    current_target_idx = idx

        return current_target_idx

    # def visualize_trajectory_on_image_fast(self, image):
    #     """å¯è§†åŒ–è½¨è¿¹ï¼ˆä½¿ç”¨æ–°çš„è½¨è¿¹ç‚¹ï¼‰"""
    #     # è·å–æœ€è¿‘çš„è½¨è¿¹ç‚¹ï¼ˆä½¿ç”¨æ–°æ¥å£ï¼‰
    #     recent_waypoints = self.trajectory_manager.get_control_waypoints(lookahead_distance=30.0)
    #
    #     if len(recent_waypoints) < 2:
    #         return
    #
    #     # è·å–è‡ªè½¦ä½ç½®
    #     ego_location = self.ego_vehicle.get_location()
    #     ego_x, ego_y = ego_location.x, ego_location.y
    #
    #     # å¯è§†åŒ–å‚æ•°
    #     scale = 20
    #     img_center_x = self.image_width // 2
    #     img_center_y = self.image_height
    #
    #     # ç»˜åˆ¶è½¨è¿¹çº¿å’Œç‚¹
    #     points_to_draw = []
    #     for wp in recent_waypoints:
    #         # è½¬æ¢ä¸ºå›¾åƒåæ ‡ï¼ˆç®€åŒ–æŠ•å½±ï¼‰
    #         rel_x = wp.world_x - ego_x
    #         rel_y = wp.world_y - ego_y
    #
    #         img_x = int(img_center_x + rel_y * scale)
    #         img_y = int(img_center_y - rel_x * scale)
    #
    #         # è¾¹ç•Œæ£€æŸ¥
    #         if 0 <= img_x < self.image_width and 0 <= img_y < self.image_height:
    #             points_to_draw.append((img_x, img_y, wp))
    #
    #     # ç»˜åˆ¶è½¨è¿¹çº¿ï¼ˆç»¿è‰²ï¼‰
    #     for i in range(1, len(points_to_draw)):
    #         cv2.line(image, points_to_draw[i - 1][:2], points_to_draw[i][:2], (0, 255, 0), 2)
    #
    #     # ç»˜åˆ¶è½¨è¿¹ç‚¹
    #     for img_x, img_y, wp in points_to_draw[-10:]:  # åªç»˜åˆ¶æœ€å10ä¸ªç‚¹
    #         # æ ¹æ®æ›²ç‡æ”¹å˜ç‚¹çš„é¢œè‰²
    #         if wp.curvature > 0.1:  # å¼¯é“
    #             color = (0, 255, 255)  # é»„è‰²
    #         else:  # ç›´é“
    #             color = (0, 255, 0)  # ç»¿è‰²
    #         cv2.circle(image, (img_x, img_y), 3, color, -1)
    #
    #         # ç»˜åˆ¶åˆ‡çº¿æ–¹å‘
    #         if len(points_to_draw) > 5:  # åªåœ¨æœ‰è¶³å¤Ÿç‚¹æ—¶ç»˜åˆ¶
    #             tangent_length = 15
    #             end_x = int(img_x + tangent_length * math.cos(wp.tangent_angle))
    #             end_y = int(img_y - tangent_length * math.sin(wp.tangent_angle))
    #             cv2.arrowedLine(image, (img_x, img_y), (end_x, end_y), (255, 0, 0), 1)
    # æ›¿æ¢ç°æœ‰çš„visualize_trajectory_on_image_fastæ–¹æ³•ï¼š
    # def visualize_trajectory_3d_realtime(self):
    #     """å®æ—¶3Dè½¨è¿¹å¯è§†åŒ–"""
    #     if not self.visualization_config['enable_3d_trajectory']:
    #         return
    #
    #     # æ§åˆ¶æ›´æ–°é¢‘ç‡
    #     self.visualization_config['frame_counter'] += 1
    #     if self.visualization_config['frame_counter'] % self.visualization_config['update_frequency'] != 0:
    #         return
    #
    #     try:
    #         # 1. åŸºæœ¬è½¨è¿¹å¯è§†åŒ–
    #         self.trajectory_visualizer.visualize_trajectory_3d(
    #             self.trajectory_manager,
    #             show_curvature=self.visualization_config['enable_curvature_visualization'],
    #             show_tangents=self.visualization_config['enable_tangent_visualization'],
    #             show_speed=self.visualization_config['enable_speed_visualization']
    #         )
    #
    #         # 2. å‰ç»è·¯å¾„å¯è§†åŒ–ï¼ˆç”¨äºæ§åˆ¶ï¼‰
    #         if self.visualization_config['enable_lookahead_visualization']:
    #             self.trajectory_visualizer.visualize_lookahead_path(
    #                 self.trajectory_manager,
    #                 self.ego_vehicle,
    #                 lookahead_distance=30.0
    #             )
    #
    #         # 3. é¢å¤–çš„å¯†é›†è½¨è¿¹å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰
    #         # self.trajectory_visualizer.visualize_trajectory_dense(
    #         #     self.trajectory_manager,
    #         #     point_interval=2.0
    #         # )
    #
    #     except Exception as e:
    #         print(f"3D trajectory visualization error: {e}")

    # def update_display_text(self, image, ego_speed, target_speed, desired_speed, trajectory_info, processing_time):
    #     """æ›´æ–°æ˜¾ç¤ºæ–‡æœ¬ï¼Œå¢åŠ è½¨è¿¹ä¿¡æ¯"""
    #     texts = [
    #         (f"Ego Speed: {ego_speed:.1f} km/h", (10, 30), (0, 255, 0)),
    #         (f"Target Speed: {target_speed:.1f} km/h", (10, 60), (0, 0, 255)),
    #         (f"Target Desired: {desired_speed:.1f} km/h", (10, 90), (255, 0, 255)),
    #         (f"Process Time: {processing_time:.2f}ms", (10, 120), (255, 255, 255))
    #     ]
    #
    #     # æ·»åŠ è½¨è¿¹ä¿¡æ¯
    #     if trajectory_info:
    #         texts.extend([
    #             (f"Traj Points: {trajectory_info['waypoint_count']}", (10, 150), (255, 255, 0)),
    #             (f"Traj Length: {trajectory_info['total_length']:.1f}m", (10, 180), (255, 255, 0)),
    #             (f"Curvature: {trajectory_info.get('current_curvature', 0.0):.3f}", (10, 210), (255, 255, 0))
    #         ])
    #
    #     # æ·»åŠ å¹³å‡å¸§ç‡æ˜¾ç¤º
    #     if self.frame_times:
    #         avg_frame_time = np.mean(self.frame_times)
    #         fps = 1000.0 / avg_frame_time
    #         texts.append((f"FPS: {fps:.1f}", (10, 240), (0, 255, 255)))
    #
    #     for text, pos, color in texts:
    #         cv2.putText(image, text, pos, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

    # def show_performance_stats(self):
    #     """æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡"""
    #     # # å¸§ç‡ç»Ÿè®¡
    #     # if self.frame_times:
    #     #     avg_frame_time = np.mean(self.frame_times)
    #     #     fps = 1000.0 / avg_frame_time
    #     #     print(f"\nFrame Rate Statistics:")
    #     #     print(f"  Average FPS: {fps:.1f}")
    #     #     print(f"  Average frame time: {avg_frame_time:.2f} ms")
    #     #     print(f"  Max frame time: {np.max(self.frame_times):.2f} ms")
    #
    #     # è½¨è¿¹å¤„ç†ç»Ÿè®¡
    #     traj_stats = self.trajectory_manager.get_performance_stats()
    #     if traj_stats:
    #         print(f"\nTrajectory Processing Statistics:")
    #         for key, value in traj_stats.items():
    #             print(f"  {key}: {value}")

    def get_lane_offset(self):
        """è·å–è½¦è¾†ç›¸å¯¹äºè½¦é“ä¸­å¿ƒçš„åç§»é‡"""
        if self.world is None:
            return 0.0

        carla_map = self.world.get_map()
        if carla_map is None:
            return 0.0

        vehicle_location = self.ego_vehicle.get_location()
        self.current_waypoint = carla_map.get_waypoint(
            vehicle_location,
            project_to_road=True,
            lane_type=carla.LaneType.Driving
        )

        if self.current_waypoint is None:
            return 0.0

        lane_center = self.current_waypoint.transform.location
        lane_direction = self.current_waypoint.transform.get_forward_vector()

        to_center_vector = carla.Vector3D(
            lane_center.x - vehicle_location.x,
            lane_center.y - vehicle_location.y,
            0
        )

        right_direction = carla.Vector3D(
            -lane_direction.y,
            lane_direction.x,
            0
        ).make_unit_vector()

        offset = to_center_vector.dot(right_direction)
        return offset

    def generate_target(self):
        """ä¸»å¾ªç¯ - é›†æˆè½¨è¿¹å¤„ç†"""
        acc_controller = ACCPlanningControl(
            self.ego_vehicle,
            target_speed_kmh=30.0,
            time_gap=2.0,
            max_follow_distance=self.max_follow_distance
        )

        # # å»¶è¿Ÿé…ç½®
        # DELAY_TIME = 0.5  # å»¶è¿Ÿ5ç§’
        # control_enabled = True
        # start_time = time.time()
        #
        # print(f"ğŸŸ¡ è‡ªè½¦å°†åœ¨ {DELAY_TIME} ç§’åå¼€å§‹...")

        try:

            self.get_extrinsic_params(self.radar, self.camera)
            self.start_time = time.time()

            frame_count = 0

            while True:
                #   å»¶è¿Ÿå‡ºå‘
                # # æ£€æŸ¥æ˜¯å¦åˆ°äº†å¯åŠ¨æ—¶é—´
                # if not control_enabled and (time.time() - start_time) >= DELAY_TIME:
                #     control_enabled = True
                #     print("ğŸŸ¢ è‡ªè½¦å¼€å§‹å‡ºå‘ï¼")


                # # å¸§æ—¶é—´ç›‘æ§
                # current_frame_time = time.perf_counter()
                # if self.last_frame_time is not None:
                #     frame_time = (current_frame_time - self.last_frame_time) * 1000
                #     self.frame_times.append(frame_time)
                # self.last_frame_time = current_frame_time

#å‰è½¦æ§åˆ¶
                if self.target_speed_controller:
                    self.target_speed_controller.update()
                    current_desired_speed = self.target_speed_controller.get_current_desired_speed()

                self.world.tick()


                # è½¨è¿¹å¤„ç†æ€§èƒ½è®¡æ—¶
                traj_start_time = time.perf_counter()
                if self.latest_camera_image is not None:
                    image_with_radar = self.latest_camera_image.copy()
                    ego_speed = self.get_vehicle_speed(self.ego_vehicle)
                    target_speed = self.get_vehicle_speed(self.target_vehicle) if self.target_vehicle else 0.0
                    vehicle_distance = self.get_vehicle_distance(self.ego_vehicle, self.target_vehicle)

                    #ç›®æ ‡æ£€æµ‹å’Œè½¨è¿¹å¤„ç† ===
                    track_id = self.track_id.copy() if self.track_id is not None else []
                    target_info = None
                    trajectory_waypoint = None
                    trajectory_info = None

                    if track_id:
                        try:
                            projected_points = self.project_radar_to_camera(track_id)
                            current_target_idx = self.find_best_target(track_id, projected_points)

                            # ç»˜åˆ¶æ‰€æœ‰æ£€æµ‹åˆ°çš„ç›®æ ‡
                            for idx in range(min(len(track_id), len(projected_points))):
                                if len(projected_points[idx]) >= 2:
                                    u, v = projected_points[idx][0], projected_points[idx][1]
                                    cv2.circle(image_with_radar, (u, v), 5, (255, 0, 0), -1)

                            if current_target_idx >= 0 and current_target_idx < len(projected_points):
                                # ç»˜åˆ¶é€‰ä¸­çš„ç›®æ ‡
                                u, v = projected_points[current_target_idx][0], projected_points[current_target_idx][1]
                                cv2.circle(image_with_radar, (u, v), 10, (255, 255, 255), -1)

                                cv2.putText(image_with_radar, f"id={track_id[current_target_idx][-1]:.0f}",
                                            (u + 5, v), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (150, 225, 100), 2)

                                target_info = track_id[current_target_idx]
                                # if len(target_info) >= 9 and all(np.isfinite(target_info[:9])):
                                    # === æ ¸å¿ƒï¼šå°†ç›®æ ‡ä¿¡æ¯ä¼ é€’ç»™è½¨è¿¹ç®¡ç†å™¨ ===
                                    # trajectory_waypoint = self.trajectory_manager.add_target_info_realtime(
                                    #     target_info, self.ego_vehicle
                                    # )
                                    # self.trajectory_stats['total_updates'] += 1
                                    #
                                    # # è·å–è½¨è¿¹ä¿¡æ¯ç”¨äºæ˜¾ç¤ºå’Œè®°å½•
                                    # trajectory_info = self.trajectory_buffer.get_info()
                                    # if trajectory_waypoint:
                                    #     trajectory_info['current_curvature'] = trajectory_waypoint.curvature
                                    #     trajectory_info['current_tangent_angle'] = trajectory_waypoint.tangent_angle
                                    #     self.trajectory_stats['successful_fits'] += 1

                        except Exception as e:
                            print(f"Target detection/trajectory error: {e}")
                    #
                    # # è®¡ç®—è½¨è¿¹å¤„ç†æ—¶é—´
                    # traj_processing_time = (time.perf_counter() - traj_start_time) * 1000

                    # # === å‡†å¤‡ä¼ é€’ç»™æ§åˆ¶å™¨çš„è½¨è¿¹æ•°æ® ===
                    # control_trajectory = None
                    # if self.trajectory_buffer.is_valid():
                    #     # è·å–å‰ç»è½¨è¿¹ç‚¹ç”¨äºæ§åˆ¶
                    #     control_waypoints = self.trajectory_manager.get_control_waypoints(lookahead_distance=30.0)
                    #     if control_waypoints:
                    #         control_trajectory = {
                    #             'waypoints': control_waypoints,
                    #             'target_waypoint': trajectory_waypoint,
                    #             'is_valid': True,
                    #             'waypoint_count': len(control_waypoints),
                    #             'curvature_profile': self.trajectory_manager.get_trajectory_curvature_profile()
                    #         }


                    # # è®°å½•æ•°æ®ï¼ˆå¢åŠ è½¨è¿¹ä¿¡æ¯ï¼‰
                    # target_world_x = trajectory_waypoint.world_x if trajectory_waypoint else 0.0
                    # target_world_y = trajectory_waypoint.world_y if trajectory_waypoint else 0.0
                    # target_curvature = trajectory_waypoint.curvature if trajectory_waypoint else 0.0
                    # target_tangent_angle = trajectory_waypoint.tangent_angle if trajectory_waypoint else 0.0

                    current_time = time.time() - self.start_time

                    # è®¡ç®—æœŸæœ›è·Ÿè½¦è·ç¦»
                    desired_distance = self.calculate_desired_following_distance(ego_speed, time_gap=2.0,
                                                                                 min_distance=5.0)

                    # å†™å…¥CSVæ•°æ®
                    self.csv_writer.writerow([
                        current_time,
                        ego_speed,
                        target_speed,
                        vehicle_distance,  # å®é™…è·ç¦»
                        desired_distance,  # æœŸæœ›è·ç¦»
                        self.get_lane_offset()
                    ])
                    self.csv_file.flush()

                    # # æ˜¾ç¤ºä¿¡æ¯
                    # if frame_count % 5 == 0:  # æ¯5å¸§æ›´æ–°ä¸€æ¬¡æ˜¾ç¤º
                    #     self.update_display_text(image_with_radar, ego_speed, target_speed,
                    #                              current_desired_speed, trajectory_info, traj_processing_time)

                    # å¯è§†åŒ–è½¨è¿¹
                    #  self.visualize_trajectory_on_image_fast(image_with_radar)
                    # å¯è§†åŒ–è½¨è¿¹ï¼ˆ3Dï¼‰
                    # self.visualize_trajectory_3d_realtime()

                    lane_center = 510
                    # è½¦é“çº¿æ£€æµ‹ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
                    try:
                        lane_windows, lane_image, detected_windows = self.lane_detector.lane_detect(image_with_radar)
                        valid_row = None
                        for row in lane_windows:
                            if len(row) == 6 and row[2] == 1 and row[5] == 1:
                                valid_row = row
                                break
                        if valid_row is not None:
                            lane_center = (valid_row[0] + valid_row[3]) / 2
                            cv2.putText(image_with_radar, f"Lane Center: {lane_center:.1f} px", (10, 270),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                    except Exception as e:
                        print(f"Lane detection error: {e}")

                    # ===å°†è½¨è¿¹ä¼ é€’ç»™æ§åˆ¶å™¨ ===
                    try:
                        # if control_trajectory and control_trajectory['is_valid']:

                            # ä½¿ç”¨è½¨è¿¹ä¿¡æ¯è¿›è¡Œæ§åˆ¶
                            #control = acc_controller.update_with_trajectory(target_info, control_trajectory,(lane_center-510)/100)
                        control = acc_controller.cruise_control((lane_center-510)/150, target_info)
                        if control.brake < 0.01 :
                            control.brake = 0
                        self.ego_vehicle.apply_control(control)
                        #else:
                            # å›é€€åˆ°åŸæœ‰çš„ç‚¹æ§åˆ¶ lane_center-510
                            #control = acc_controller.update(target_info,(lane_center-510)/100, target_info)
                            #control = acc_controller.cruise_control((lane_center - 510) / 100,target_info)
                        # if control_enabled:
                        #     self.ego_vehicle.apply_control(control)
                        # else:
                        #     # ä¿æŒåœæ­¢
                        #     stop_control = carla.VehicleControl(throttle=0.0, brake=1.0, steer=0.0)
                        #     self.ego_vehicle.apply_control(stop_control)
                        #

                        print(control)
                    except Exception as e:
                        print(f"ACC control error: {e}")

                    # æ˜¾ç¤ºå›¾åƒ
                    cv2.imshow("Radar and Objects on Camera", image_with_radar)
                    # cv2.imshow("lane_image", lane_image)
                    # cv2.imwrite("C:\App\carla\CARLA_0.9.14\images\lane_frame_" +str(frame_count) + ".jpg", lane_image)
                    cv2.waitKey(1)

                    frame_count += 1

        except KeyboardInterrupt:
            print("\nStopped by user.")
        except Exception as e:
            print(f"Error: {e}")
            import traceback
            traceback.print_exc()
        finally:
            print("Cleaning up...")
            # self.show_performance_stats()
            cv2.destroyAllWindows()
            self.csv_file.close()
            self.destroy()


    def destroy(self):
        self.radar.stop()
        self.camera.stop()
        self.lidar.stop()
        self.radar.destroy()
        self.camera.destroy()
        self.lidar.destroy()
        for vehicle in self.vehicles:
            vehicle.destroy()
        self.ego_vehicle.destroy()
        print(f"Destroyed {len(self.vehicles)} vehicles, ego vehicle, radar, camera, and LIDAR.")

def main():
    acc_actor = acc()
    thread_1 = threading.Thread(target=acc_actor.radar.listen, args=(acc_actor.radar_callback,), name='T1')
    thread_2 = threading.Thread(target=acc_actor.camera.listen, args=(acc_actor.camera_callback,), name='T2')
    thread_3 = threading.Thread(target=acc_actor.lidar.listen, args=(acc_actor.lidar_callback,), name='T3')
    thread_1.start()
    thread_2.start()
    thread_3.start()
    try:
        acc_actor.generate_target()
    except KeyboardInterrupt:
        print("Program interrupted.")
    finally:
        thread_1.join()
        thread_2.join()
        thread_3.join()
        print("All threads terminated.")


if __name__ == '__main__':
    main()